# 使用联邦学习统计影响学生学习的相关因素
## 项目介绍
本项目基于山东大学网络空间安全学院和蚂蚁集团合作的隐语secretflow数据要素流通创意大赛。

文件来自参赛小组四十二。

本项目主要目标是通过联邦学习来研究影响学生学习的因素，实验主要使用secretflow隐语开发平台。该项目的目的是在不暴露各方所持有的数据集的条件下，以透明和可访问的方式呈现它们的联邦学习结果。
## 目录
* [使用联邦学习统计影响学生学习的相关因素](#使用联邦学习统计影响学生学习的相关因素)
    * [项目介绍](#项目介绍)
    * [目录](#目录)
    * [现实需求](#现实需求)
    * [样本收集处理](#样本收集处理)
    * [预处理](#预处理)
       * [现实需求下的处理](#现实需求下的处理)
    * [机器学习](#机器学习)
       * [结果分析](#结果分析)
    * [项目参考](#项目参考)

## 现实需求
现如今很多学校在探索如何提升学生的学习成绩，不同学校掌握着不同的样本ID空间，构成了一个水平联邦学习。考虑到实际情况中不同学校不应该持有其他学校学生的隐私信息，所以我们使用隐语联邦学习来在不暴露各方所持有的数据集的条件下，研究学生的学习情况。在两个数据集的用户特征重叠较多而用户重叠较少的情况下，我们把数据集按照横向(即用户维度)切分，并取出双方用户特征相同而用户不完全相同的那部分数据进行训练，该场景下，可以将来自各方的样本联合训练得到一个相比单方训练表现更好的模型。
![v2-caa71b739f1aab710925677ffb12bec9_r](https://github.com/user-attachments/assets/fb5fb53c-0525-4239-8719-65133e5c73dd)

之所以选择这个主题，主要有一下了两个方面的考虑：
首先是在当今社会保护未成年的大环境下，学生信息受到全社会的保护，因此，通过学生信息去预测学生成绩的行为要以隐私优先，这就充分发挥了隐语平台和隐私计算的优势。
另一方面，学生信息大部分和成绩并没有非常明显的联系。也许我们可以说父母学历低对于学生学习有负面影响，但是一名学生周末是否有空闲时间，平时是否参加社团活动，这些特征和学生的学习成绩究竟有什么关系，是我们不用机器很难得出结论的。这一部分就体现出我们使用的机器学习的优势，可以将人脑难以聚合的特征和学习成绩建立起逻辑关系。

除此之外，我们搜寻到的数据还有一些特征，比如说样本容量比较小，优点是方便我们测试数据，缺点是实验测试出来的数据准确度相对较低，需要较高的迭代步数去确保学习结果的精确度。

## 样本收集处理
数据收集来自https://archive.ics.uci.edu/dataset/320/student+performance 主要包含学生的各种信息例如年级，父母状况如下图所示。收集好后的数据以csv形式存储，在上述文件夹中student文件即为数据介绍文件，student.mat文件为数据经过调整后的文件。
![WPS图片(1)](https://github.com/user-attachments/assets/c3c4715e-f49b-4cbe-b711-0afd9f4a851a)

## 预处理
学校A和学校B，两个学校各自有自己的学生样本，他们在各自的本地先运行自己学生样本的机器学习结果，最后再整合起来。
### 现实需求下的处理
1.考虑到很多学生不一定愿意提交自己的部分隐私数据，比如我们的数据集中统计了学生的家庭氛围和父母婚姻状况。尽管我们搜索到的这份数据集中没有空缺，但是现实中很有可能会存在数据空缺的情况，再这种情况下，我们设计了使用中位数填补空缺的机制，能够让空缺不影响到我们程序的运行。

2.实验数据中有不少数据存在方差过大的问题，还是考虑我们数据集的实际情况：在我们数据集中统计了上学期逃课情况，而这个数据结果很容易分布在两级，即不逃课的人基本从来不逃，逃课的人逃的课数都数不过来。方差过大就导致数据集训练起来很难，我们采用对数据整体标准化的方法，降低数据的方差，以便于机器去进行学习。

3.我们统计的数据很多都是以简答题呈现的，数据呈现上来基本都是字符串的形式，这对于我们的机器学习的效率有所影响，所以在不影响作答结果的情况下，我们将统计的数据全部转化为整型数字，便于我们机器学习的步骤。

4.我们预设的环境是两个学校一起进行联邦学习，后来我们在实验中发现，如果两个学校存在同一名转校生，即一名学生从一个学校转校到了另一个学校，这就会导致同一份数据统计了两次。我们采用PSI隐私求交去去重，确保了我们项目应对实际情况下的效率。
## 机器学习
我们采用的是全连接的神经网络，主要考虑到的是我们统计样本的特征。一个学生每天学习1小时可以考50分，不代表每天学2小时就能考100分。这种非线性特征非常适合全连接的神经网络。同时因为我们的数据集并不算复杂，总共只有400项左右的数据，太多层反而会浪费计算能力。所以我们在权衡之后，决定使用四层的全连接神经网络。
### 结果分析
最后的结果我们尝试了多个迭代次数下的数据：

我们分别尝试了在20次迭代，40次迭代，400次迭代的情况下机器学习的结果，数据显示，随着迭代次数的增加，数据的精确度是上升的，当迭代次数来到200左右时，结果的精确度基本固定在百分之三十左右。在迭代次数固定的情况下，随着程序的进行，结果的精确度总体上也是增加的。考虑到我们的样本量比较小，如果扩大样本量和计算量，依照当前的计算结果趋势，机器学习的结果应该会不断上升。
## 项目参考
实例参考主要来自https://www.secretflow.org.cn/zh-CN/docs/secretflow/v1.9.0b1/
项目主要使用隐语平台库编写。
